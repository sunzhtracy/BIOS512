{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.3.3"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4d684172-4b94-42cf-bda2-e11952420d86","cell_type":"markdown","source":"# Homework 10\n#### Course Notes\n**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19","metadata":{}},{"id":"d839a5ba-62f4-4699-baea-018afda70786","cell_type":"markdown","source":"## Question 1\n#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified.","metadata":{}},{"id":"9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49","cell_type":"markdown","source":"#### a) Make a function to tokenize the text.","metadata":{}},{"id":"fe0f2f52-63f1-4af5-9b34-c9d820b3ac8c","cell_type":"code","source":"tokenize <- function(text) {\ntokens <- unlist(strsplit(tolower(text), \"\\\\s+\"))\ntokens[tokens != \"\"]\n}","metadata":{"trusted":true},"outputs":[],"execution_count":2},{"id":"86145513-294b-4894-a02c-8ae60e2c616e","cell_type":"markdown","source":"#### b) Make a function generate keys for ngrams.","metadata":{}},{"id":"2caf38d7-5687-4539-b54b-bcc589688127","cell_type":"code","source":"generate_keys <- function(tokens, n) {\n  keys <- list()\n  L <- length(tokens)\n  # if there aren't enough tokens to form any n-gram, return empty list\n  if (L <= n) return(keys)\n\n  for (i in seq_len(L - n)) {\n    key <- tokens[i:(i + n - 1)]\n    next_word <- tokens[i + n]\n    keys[[length(keys) + 1]] <- list(key = key, next_word = next_word)\n  }\n  keys\n}","metadata":{"trusted":true},"outputs":[],"execution_count":3},{"id":"52988c2c-b230-467f-b519-72bc85b93b43","cell_type":"markdown","source":"#### c) Make a function to build an ngram table.","metadata":{}},{"id":"efd1cc5e-8210-4cf0-8acb-460651b683e5","cell_type":"code","source":"build_ngram_table <- function(tokens, n) {\n  table <- list()\n  keys <- generate_keys(tokens, n)\n  if (length(keys) == 0) return(table)\n\n  for (pair in keys) {\n    key_str <- paste(pair$key, collapse = \" \")\n    if (!key_str %in% names(table)) {\n      table[[key_str]] <- character(0)\n    }\n    table[[key_str]] <- c(table[[key_str]], pair$next_word)\n  }\n  table\n}","metadata":{"trusted":true},"outputs":[],"execution_count":4},{"id":"1ca6db37-abce-4705-9784-e1b898174f00","cell_type":"markdown","source":"#### d) Function to digest the text.","metadata":{}},{"id":"d1242829-5867-4404-bf72-5aba7ffe50d3","cell_type":"code","source":"digest_text <- function(text, n) {\ntokens <- tokenize(text)\nbuild_ngram_table(tokens, n)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":5},{"id":"53fff313-0f13-479b-94df-7588c19fdd3d","cell_type":"markdown","source":"#### e) Function to digest the url.","metadata":{}},{"id":"4e0cc58c-6ed7-49fc-9c95-19e212985b39","cell_type":"code","source":"digest_url <- function(url, n) {\ntext <- paste(readLines(url, warn = FALSE), collapse = \" \")\ndigest_text(text, n)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":6},{"id":"c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a","cell_type":"markdown","source":"#### f) Function that gives random start.","metadata":{}},{"id":"ee61f541-5927-4653-8c75-991e6c80e3dd","cell_type":"code","source":"random_start <- function(table) {\nsample(names(table), 1)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":7},{"id":"e998fb24-f2d6-41bc-a751-1f6accd3411f","cell_type":"markdown","source":"#### g) Function to predict the next word.","metadata":{}},{"id":"2a785ad8-cde9-49e5-8ee7-b6f9ec07068b","cell_type":"code","source":"predict_next <- function(table, key) {\nif (key %in% names(table)) {\nsample(table[[key]], 1)\n} else {\nNA\n}\n}","metadata":{"trusted":true},"outputs":[],"execution_count":8},{"id":"347f4002-4932-42c4-a4af-8689293a5857","cell_type":"markdown","source":"#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used.","metadata":{}},{"id":"62ae644c-767a-4cd3-8153-121b16ac69d0","cell_type":"code","source":"generate_text <- function(table, start = NULL, length = 20) {\nif (is.null(start)) {\nkey <- random_start(table)\n} else {\nkey <- start\nif (!(key %in% names(table))) {\nkey <- random_start(table)\n}\n}\n\n\noutput <- unlist(strsplit(key, \" \"))\nn <- length(output)\n\n\nfor (i in seq_len(length)) {\nnext_word <- predict_next(table, key)\nif (is.na(next_word)) break\noutput <- c(output, next_word)\nkey <- paste(output[(length(output) - n + 1):length(output)], collapse = \" \")\n}\n\n\npaste(output, collapse = \" \")\n}","metadata":{"trusted":true},"outputs":[],"execution_count":9},{"id":"3b742c67-907c-4bc7-8df1-c84fa65a7554","cell_type":"markdown","source":"## Question 2\n#### For this question, set `seed=2025`.\n#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n#### ii) Using n=3, with no start word, with length=15.","metadata":{}},{"id":"6bebd849-e003-4573-bf91-7bc19930015b","cell_type":"code","source":"set.seed(2025)\nread_corpus <- function(path) {\n  paste(readLines(path, warn = FALSE), collapse = \" \")\n}\ngrimm_text <- read_corpus(\"grimms_fairy_tales.txt\")\ngrimm_table_3 <- digest_text(grimm_text, n = 3)\ngen1a <- generate_text(grimm_table_3, start = \"the king\", length = 15)\ncat(\"Grimm, with 'the king':\", gen1a, \"\\n\")\ngen1b <- generate_text(grimm_table_3, start = NULL, length = 15)\ncat(\"Grimm, random start:\", gen1b, \"\\n\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Grimm, with 'the king': the water, i will change your little hut into a splendid castle.” then the fisherman got up and \nGrimm, random start: of each other. the princess put the piece of cloth in her bosom, mounted her horse, and thought \n"}],"execution_count":12},{"id":"0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc","cell_type":"markdown","source":"#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n#### ii) Using n=3, with no start word, with length=15.","metadata":{}},{"id":"3d7ad5f9-c548-4e37-81fb-225f9da7e690","cell_type":"code","source":"armour_text <- read_corpus(\"ancient_armour_weapons_europe.txt\")\narmour_table_3 <- digest_text(armour_text, n = 3)\ngen2a <- generate_text(armour_table_3, start = \"the king\", length = 15)\ncat(\"Armour, with 'the king':\", gen2a, \"\\n\")\ngen2b <- generate_text(armour_table_3, start = NULL, length = 15)\ncat(\"Armour, random start:\", gen2b, \"\\n\")","metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"Warning message in file(con, \"r\"):\n“cannot open file 'ancient_armour_weapons_europe.txt': No such file or directory”\n"},{"ename":"ERROR","evalue":"Error in file(con, \"r\"): cannot open the connection\n","traceback":["Error in file(con, \"r\"): cannot open the connection\nTraceback:\n","1. read_corpus(\"ancient_armour_weapons_europe.txt\")","2. paste(readLines(path, warn = FALSE), collapse = \" \")   # at line 3 of file <text>","3. readLines(path, warn = FALSE)   # at line 3 of file <text>","4. file(con, \"r\")"],"output_type":"error"}],"execution_count":13},{"id":"25fb37ad-8e7c-4e62-afc0-ba46d46401fc","cell_type":"markdown","source":"#### c) Explain in 1-2 sentences the difference in content generated from each source.\nThe text generated from Grimm’s Fairy Tales is more narrative, fairy-tale–like, with common storytelling words (e.g. “once upon a time,” “forest,” “king”), while the model trained on Ancient Armour and Weapons produces more technical, historical, and descriptive language (e.g. “warriors,” “iron,” “shields,” “swords”) reflecting the subject-matter of that corpus.","metadata":{}},{"id":"56e45972-f441-4d07-9073-fcddd6146cbd","cell_type":"markdown","source":"## Question 3\n#### a) What is a language learning model? \nA language learning model is a statistical or machine-learning system that learns patterns in text so it can predict the next word, generate text, classify language, or otherwise process natural language. It learns these patterns from training data, building probabilities of word sequences so that it can produce human-like outputs.\n#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?\nRunning a language model locally means you must have both the code and the model weights saved on your computer, and use offline software to execute it.","metadata":{}},{"id":"b85a743b-f814-4a53-96e6-8bccb3d34ab8","cell_type":"markdown","source":"## Question 4\n#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n| Term | Meaning |  \n|------|---------|\n| **Shell** |The shell is the program that interprets your command. When you type mkdir project, the shell (e.g., bash, zsh) reads the text, parses it, and runs the mkdir program with the argument project.  |\n| **Terminal emulator** |The terminal emulator is the window or application you type into. So when you type mkdir project, you're typing into a terminal emulator that passes your text to the shell.  |\n| **Process** |A process is a running program. When you enter mkdir project, the shell creates a new process to run the mkdir command.  |\n| **Signal** |A signal is a message sent to a process to control it. mkdir project usually doesn't involve signals unless you send one manually.  |\n| **Standard input** |stdin is data input sent into a process.  |\n| **Standard output** |stdout is what a process prints out.  |\n| **Command line argument** |A command line argument is extra information passed to a program after the command name.  |\n| **The environment** |The environment is a set of variables the shell passes to processes.  |","metadata":{}},{"id":"1332ff27-ca3f-4f7e-b4b9-07ead0358dd2","cell_type":"markdown","source":"## Question 5\n#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n#### a) What are the programs?\nThe programs being run are:find, xargs, grep\n#### b) Explain what this command is doing, part by part.\nThe entire command:\nFinds every R script (*.R, case-insensitive) in the current directory and all subdirectories.\nSends that list of files into xargs.\nxargs passes those filenames to grep read_csv.\ngrep searches each R script for lines containing the function read_csv.\nThe result is a list of lines in your R files where read_csv is used.","metadata":{}},{"id":"69771ac7-865e-4d82-aa25-a39e7c1ab095","cell_type":"markdown","source":"## Question 6\n#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n#### a) Show the response when you run `docker run hello-world`.\n#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n#### c) How do you log in to the RStudio server?","metadata":{}}]}